{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" live (realtime) latent space interpolations of trained models \"\"\"\n",
    "\n",
    "import argparse\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from MSG_GAN.GAN import Generator, Discriminator\n",
    "from generate_multi_scale_samples import progressive_upscaling\n",
    "from torchvision.utils import make_grid\n",
    "from math import ceil, sqrt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the device for running the demo:\n",
    "#device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "device = th.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dynamic_range(data, drange_in=(-1, 1), drange_out=(0, 1)):\n",
    "    \"\"\"\n",
    "    adjust the dynamic colour range of the given input data\n",
    "    :param data: input image data\n",
    "    :param drange_in: original range of input\n",
    "    :param drange_out: required range of output\n",
    "    :return: img => colour range adjusted images\n",
    "    \"\"\"\n",
    "    if drange_in != drange_out:\n",
    "        scale = (np.float32(drange_out[1]) - np.float32(drange_out[0])) / (\n",
    "                np.float32(drange_in[1]) - np.float32(drange_in[0]))\n",
    "        bias = (np.float32(drange_out[0]) - np.float32(drange_in[0]) * scale)\n",
    "        data = data * scale + bias\n",
    "    return th.clamp(data, min=0, max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(gen, point):\n",
    "    \"\"\"\n",
    "    obtain an All-resolution grid of images from the given point\n",
    "    :param gen: the generator object\n",
    "    :param point: random latent point for generation\n",
    "    :return: img => generated image\n",
    "    \"\"\"\n",
    "    images = list(map(lambda x: x.detach(), gen(point)))[1:]\n",
    "    images = [adjust_dynamic_range(image) for image in images]\n",
    "    images = progressive_upscaling(images)\n",
    "    images = list(map(lambda x: x.squeeze(dim=0), images))\n",
    "    image = make_grid(\n",
    "        images,\n",
    "        nrow=int(ceil(sqrt(len(images))))\n",
    "    )\n",
    "    return image.cpu().numpy().transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "args = Object()\n",
    "args.generator_file = 'models/005/GAN_GEN_007000.pth'\n",
    "args.discriminator_file = 'models/005/GAN_DIS_007000.pth'\n",
    "args.depth = 5 #5 == 64x64\n",
    "args.latent_size = 512\n",
    "args.num_points = 1\n",
    "args.transition_points = 120\n",
    "args.smoothing = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model for the demo\n",
    "gen = th.nn.DataParallel(\n",
    "    Generator(\n",
    "        depth=args.depth,\n",
    "        latent_size=args.latent_size))\n",
    "gen.load_state_dict(th.load(args.generator_file, map_location=str(device)))\n",
    "gen.cuda()\n",
    "\n",
    "dis = Discriminator(depth=args.depth, feature_size=args.latent_size, gpu_parallelize=True)\n",
    "dis.load_state_dict(th.load(args.discriminator_file, map_location=str(device)))\n",
    "dis.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the set of points:\n",
    "total_frames = args.num_points * args.transition_points\n",
    "#all_latents = th.randn(total_frames, args.latent_size).to(device)\n",
    "\n",
    "def normalize(vec):    \n",
    "    return (vec / vec.norm(dim=-1, keepdim=True)) * sqrt(args.latent_size)\n",
    "\n",
    "variance = 10.0\n",
    "\n",
    "\"\"\"\n",
    "dim1 = 10\n",
    "dim2 = 511\n",
    "start_latent = normalize(th.ones([args.transition_points, args.latent_size]).to(device))\n",
    "end_latent = th.ones([args.latent_size])\n",
    "end_latent[dim1:dim2] = 0.0\n",
    "end_latent = normalize(end_latent.expand(args.transition_points, args.latent_size).to(device))\n",
    "\"\"\"\n",
    "#end_latent = th.ones([args.transition_points, args.latent_size]).to(device))\n",
    "\n",
    "start_latent = normalize(th.randn(args.latent_size).to(device))\n",
    "end_latent = normalize(start_latent+variance*normalize(th.randn(args.latent_size)).to(device))\n",
    "\n",
    "linear_ramp = th.linspace(0, 1, args.transition_points).unsqueeze(1).expand(args.transition_points, args.latent_size).to(device)\n",
    "\n",
    "all_latents = start_latent * linear_ramp + end_latent * (1.0 - linear_ramp)\n",
    "\n",
    "#all_latents=normalize(all_latents)\n",
    "\n",
    "#all_latents = th.from_numpy(\n",
    "#    gaussian_filter(\n",
    "#        all_latents.cpu(),\n",
    "#        [args.smoothing * args.transition_points, 0], mode=\"wrap\"))\n",
    "\n",
    "#all_latents = (all_latents /\n",
    "#               all_latents.norm(dim=-1, keepdim=True)) * sqrt(args.latent_size)\n",
    "\n",
    "print(all_latents)\n",
    "\n",
    "start_point = th.unsqueeze(all_latents[0], dim=0)\n",
    "points = all_latents[1:]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.axis(\"off\")\n",
    "shower = plt.imshow(get_image(gen, start_point))\n",
    "\n",
    "print('all_latents size: {}'.format(all_latents.size()))\n",
    "print(start_point[0][0:8])\n",
    "print(points[-1][0:8])\n",
    "\n",
    "start_img = gen(start_point)\n",
    "score1 = dis(start_img)\n",
    "score2 = dis(gen(th.unsqueeze(points[-1], dim=0)))\n",
    "print('start_img: {} {}'.format(len(start_img),start_img[-1].size()))\n",
    "print('score: {} -> {}'.format(score1[0], score2[0]))\n",
    "\n",
    "def init():\n",
    "    return shower,\n",
    "\n",
    "def update(point):\n",
    "    shower.set_data(get_image(gen, th.unsqueeze(point, dim=0)))\n",
    "    return shower,\n",
    "\n",
    "# define the animation function\n",
    "anim = FuncAnimation(fig, update, frames=points,\n",
    "                    init_func=init, interval=20, blit=True)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
